                                     Linux
=========================================================================================================
                                 Unix vs Linux
=========================================================================================================
Initially all computers were designed for one task and not time-sharing. This means that there was one
computer for salary calculations, one for word processing and user couldn`t perform multiple tasks
simultaneously, like do word processing and listen music. To overcome those issues the Multics OS was
developed as collaborative project between MIT, General Electronics and Bell Labs. Multics wat time
sharing OS meaning that many programs can share hardware resources and switch on finite time intervals.
Due to the very small intervals there is an illusion that multiple programs are running concurrently.

https://www.youtube.com/watch?v=jowCUo_UGts
https://thishosting.rocks/unix-vs-linux/
https://www.quora.com/What-are-the-similarities-and-differences-between-UNIX-and-Linux
https://www.guru99.com/difference-unix-vs-linux.html
=========================================================================================================
                                Windows vs Linux
=========================================================================================================

https://www.guru99.com/linux-differences.html
https://www.howtogeek.com/137096/6-ways-the-linux-file-system-is-different-from-the-windows-file-system/
---------------------------------------------------------------------------------------------------------
                               Line endings issue
---------------------------------------------------------------------------------------------------------
DOS inherited CR-LF line endings (\r\n in ascii) fro, CP/M. CR-LF was used so that the teletype machines
would return the print head to the left margin (CR = Carriage return), and then mov to the next line
(LF = line feed).
On Unix it is handled in the device driver, and when necessary translated LF to CR-LF on output to devices
that needed it.
Mac OS X before version 10 used CR for new line and versions 10+ use LF.

Vim will display CRLF as ^M. To remove it, start search and replace, and when entering search part
pres C-v + C-m to get need character. Another option is ":%s/\r/\r/g" or just clear file with dos2unix
shell utility
dos2unix <file.txt>

http://vimdoc.sourceforge.net/htmldoc/digraph.html#digraph-table
https://stackoverflow.com/questions/5843495/what-does-m-character-mean-in-vim
https://stackoverflow.com/questions/419291/historical-reason-behind-different-line-ending-at-different-platforms
---------------------------------------------------------------------------------------------------------
=========================================================================================================
                             Device/Driver Binding
=========================================================================================================
Driver binding is the process of associating a device with a device driver that can control it.
=========================================================================================================
                                     umask
=========================================================================================================
By default any created file has permissions 666 and direcotry 777. Umask can be used to unset some of
this rights. Issue `umask` to see current mask, then subtract it from defaul value and you will get
permissions of newly created files

? umask -S return default file permission of system, without applied mask
=========================================================================================================
                                     Links
=========================================================================================================
Files behind a file system are just an tree of inodes and a file is a link to an inode. A hard links creates
another file with the same underlying inode. When u delete file link is removed but inode is not deleted
unless there is no more links to it.  A symbolic link is a link to another name in the file system. When
u move/rename/delete file , this will not affect hard link since it points to background inode. In case of
soft link it will be broken. Hardlinks are valid only in scope of one filesystem and soft can span multiple.
Note that you can`t create hard link to directory (possible for symlinks), this is done to maintain acyclic
directory tree structure.

             /===> | inode    |
            /          |
    | Hard Link |  | file.txt | <=== | Soft Link |

Use hard links when original file is often moved between directories. Hard link requires directory entry
and not inode (cheaper), Symlink may point to another symlink as well as be recursive, make loops, point
to files on another machine (networt mount filesystems) which may affect time spent to open file.

ln -s /source/file /target/symlink    ## create a new symlink (fails if symlink exists already)
ln -sf /source/file /target/symlink   ## create or update a symlink
ls -l /source/file /target/symlink    ## checking for validity
ln -s /directory/*  /target/          ## link all files from one directory to another (without hidden ones)
---------------------------------------------------------------------------------------------------------
Example usage of hardlinks. There is a utility named rsync used to make periodically backups, in the case
nothing has changed, since last backup taking, it just hardlinks new backup file to previos one, since
it is cheaper to create a links then create a duplicate of that file.

---------------------------------------------------------------------------------------------------------
To find if there are symbolick links pointing to your file, you can issue
find -L / -samefile path/to/foo.txt    # find all links pointing exactly to <path/to/foo.txt>
find -L /  -xtype l -prune -samefile foo -exec ls -ld {} +  # another way
find / -lname foo.txt                  # find all links pointing to any <foo.txt>
Using inode
find -follow -inum $(ls -i foo.txt)
Or just use special utility like `symlinks`
https://stackoverflow.com/questions/6184849/symbolic-link-find-all-files-that-link-to-this-file

---------------------------------------------------------------------------------------------------------
It is possible to have a loop formed with links. To find if there is loop starting from current directory,
issue `find` with `-follow`. It should print an error if loop was detected.
find . -follow -printf ""

https://serverfault.com/questions/265598/how-do-i-find-circular-symbolic-links
---------------------------------------------------------------------------------------------------------

Dangling symlink. Symlink with an invalid target (target file doesn`t exist)

https://stackoverflow.com/questions/185899/what-is-the-difference-between-a-symbolic-link-and-a-hard-link/1531795#1531795
=========================================================================================================
                                     Users
=========================================================================================================
In linux used are defined by the uid however in life users use nicknames so uids are needed to be mapped
to them. This is done in one system files like /etc/passwd UID0 => root
To list all in system user, issue `cat /etc/passwd` and for groups `cat /etc/group`
To list logged in user, use `w` or `who`
To displays the system identifications of a specified user `id`

=========================================================================================================
                       Memory-mapped IO vs Port-mapped IO
=========================================================================================================
There are many ways to connect external devices, for instance memory mapped or port mapped IO.
Memory mapped IO is mapped into the same address space as progeam memory and/or user memory, and is
accessed in the same way. 
Port mapped IO uses a separate, dedicated address space and is accessed via dedicated set of microprocessor
instructions

https://www.bogotobogo.com/Embedded/memory_mapped_io_vs_port_mapped_isolated_io.php
=========================================================================================================
                          Sessions and process groups
=========================================================================================================
Processes are organized into sets of sessions. The session`s ID is the same as the pid of the process that
created the session through the setsid() system call. That process is known as the session leader. All
descendant processes are members pf that session unless they specifically remove themselves from it.
Sessions are controlled by a terminal from which processes in the session get their input and to which they
send their output,  This terminal is called controlling terminal of the session. A terminal can be controlling
terminal for only one session at a time.

One of the original design goals of Unix was to construct a set of simple tools that could be used together
in complex ways (through mechanisms like pipes). Another popular feature added to Unix was job control.
Process groups allow the system to keep track of which processes are working together and hecnce should
be managed together via job control. To add process to a group use int setpgid(pid_t pid, pid_t pgid);
pid => process, pgid => process group. Value of 0 can be used for pid, to specify current process and for
pgit to start a new group with pid of current process. Process who created a group is a group leader.

When the session leader exits, the process group become an ophaned. Any of leader child programgs become
children of init, but stay in their original session. Then SIGHUP is sent to all processes making most of
them terminating unless process handles it, then SIGCONT is send to such procces. This process is forvibly
disassociated from its controlling terminal and trying to write or read from terminal will cause EIO.
Session ID is not fread untill there is process running.

http://www.informit.com/articles/article.aspx?p=397655&seqNum=6
=========================================================================================================
                                   Libraries
=========================================================================================================
Libraries are simply collections of object files arranged by ar(archiver) utility
We use libraries because we can link out project to library and recompile our code without recompiling
the library. Library implementors may dont want to show code but still provide interface to using it.
However recompilation may be not so important in small projects

ar collects object files into one archive file and adds a table that tells which object files in the
archive define what symbols. The linker, ld, then binds references to a symbol in one object file to
the definition of that symbol in an object file in the archive. Static libraries use the suffix .a.
To convert object files into a static library
ar rcs libname.a obj1.o obj2.o obj3.o ...
   r    => include object file into library, replacing the old one if present
   c    => create silently if doesnt exist
   s    => maintain the table mapping symbol names to object file names???
Add object file to alread existing one
ar rcs libname.a new_obj.o

Shared library are loaded by program when it starts and any other program requiring it can use out copy.
This let us use smaller executables but entire library should be loaded into memory at runtime, therefore
it depends on count of users, whether we win in terms of memory or not. Internals of ilibrary is COW protected
meaning that any process trying to change state of library will allocate its own copy. When bug is found
it library, shared library can be easily replaced without recompile all applications using library.
The problem apperes when you give an executable to some one who doesnt have needed shared library, since
application wount work. First program using it, has penalty of finding and loading library to memory.
As well, entire library is mapped into space of a program, instead of couple object files.

Shared libraries mechanism was designed to be backward compatibility, that is application still works
when newer version is used, however ,there needs to be a way to mark libraries as incompatible with each
other for cases in which developers find it necessary to modify interfaces in a non-backward-compatible manner.

Every shared library is assigned a special name, called soname, that includes the name of the library and
a version number. When developer change interfaces, they icrement the version number, altering the name.
Most library developers attempt to maintain stable interfaces that change in an incompatible manner only
when they release a new major verison of the library.

For instance, developers of C library attempt to maintain backward compatibility for all releases of C
library with the same major number. Version 5 has gone thorugh five minor versions. Because all version 5
C libraries are intended to be backward compatible with older version, they all use the smae soname - libc.so.5
- which is related to the name of the file in which it is stored, /lib/libc.so.5.m.r , where m is the minor
version and r is the release number, Application that link against a shared library do not link directly
against /lib/libc.so.5 (for instance) even though the file exists. The ldconfig program, a standart Linux
system utility, creates a symbolic link from /lib/libc.so.5 (the soname) to /lib/libc-2.3.2.so, the real
name of the library. To upgrade library, put new so file into /lib and run ldconfing, it will update links
to point to the newest library that provides the soname.

When a new version of a library needs to be incompatible with an old version, it should be given a
different soname. For instance, to lease a new version of the C library that is incompatible with the old
one, developers used the soname libc.so.6 instead of libc.so.5. User can link application to any of there
libs, soname will point to correct version of real library.

If you want to have ur custom libraries in separate direcotry, add its path to /etc/ld.so.conf and run
ldconfig, otherwise dynamic loader wount find it in cache /etc/ld.so.cache. Another way is to prepend path
to LD_LIBRARY_PATH If you want to redefine some function (linker goes through a list of libs until finds
reqested function definition), use LD_PRELOAD. For instnace zlibc will call existing function otherwise if
gziped version exists, it transparently for application uncompresses file. This way you can exchange speed
for space. To make preload behaviour consistent on entire system, add librarry path to /etc/ld.so.preload

In case, compiler has failed to locate a library file. like following, you can issue following
make: *** No rule to make target '/usr/lib/arm-linux-gnueabihf/libreadline.a', needed by 'bin/cint'.  Stop.

1. Check if directory is present at all
   stat /usr/lib/arm-linux-gnueabihf/libreadline.a
2. If it is not, locate package that contains it
   apt-file search /usr/lib/arm-linux-gnueabihf/libreadline.a
   apt-file search libreadline.a
   apt install libreadline-dev


---------------------------------------------------------------------------------------------------------
ldconfing is a program that looks at predefined path and generates links to libs (sonames to real names
/ real name) + setting up cache (/etc/ld.so.cache). Installer must specifically modify symbolic links to
update what the linker will use for a library

It is recommended ,by standart, to install libs to 
/usr/local/lib --- not part of the system
/lib           --- required on boot
/usr/lib       --- other/most?

On each execution it is reading cache instead of going through all posible directories. This implies, that,
ldconf should be run on each DLL creation/ deletion (it is usually done with package managers )

How libs are used
- Starting up elf will cause program loader to be loaded and run
- /lib/ld-linux finds and loads all shared libs
- /etc/ld.so.conf list of directories to be searched
- Function are overloaded with /etc/ld.so.preload

Use `lld #exe` to see what libs are required (this may try to execute program therefore this is not secure)
Use `nm #lib` to list all symbols within it
---------------------------------------------------------------------------------------------------------
                                  Environment
---------------------------------------------------------------------------------------------------------
$LD_LIBRARY_PATH = colon-separated list of dir to be search first, before standart lookup.
            Alternativly, u can call loader by hand /lib/ld−linux.so.2 −−library−path PATH EXECUTABLE
$LD_PRELOAD = overriding functions
$LD_DEBUG = ?

Command example
gcc -shared
    -fpic                      => position independent code
    -W1,-soname,#my_soname     => set soname?
                                  W1 passes option to linker
    -rpath                     => runtime lib lookup path
    -o #libname                => output libname 
    -l#liblist                 => used libs

gcc −shared −Wl,−soname,my_lib.so.1 −o libmystuff.so.1.0.1 a.o b.o −lc

# Linking to executable
gcc objects.o exe -l lib
    -L dir  # extra path to directory when -l will be looked up
    -l lib  # link lib to executable

=========================================================================================================
                                    Linking
=========================================================================================================
Linking is the process of combining various pieces of code and data together to form a single executable
that can be loaded in memory. Linking can be done at compile time, at load time (by loaders) and also at
run time (by application programs).

Linker and loader perform various related but conceptually different tasks:
- Progam Loading. Copying a program image from hard disk to the main memory in order to put the profram in
  a ready-to-run state. This may involve allocating storage space or mapping virtual addresses to disk pages
- Relocation. Each input module is assigned starting address of zero by assembler/compiler.
  Relocation is the process of assigning load addresses to different parts of the program by merging all
  sections of the same type into one section. The code and data section are adjusted so they point to the
  correct runtime addresses
- Symbol Resolution. A linker`s job is to resolve the reference by noting the symbol`s location and patching
  the caller`s object code.

Loader does the program loading; the linker does the symbol resolutin; and either of them can do the relocation

At compile time, the compiler exports each global symbool as either strong or weak. Functions and initialized
global variables get strong wight, while global uninitialized variables are weak. Now, the linker resolves
the symbols using the following rules =>
1. Multiple strong symbols are not allowrd
2. Given a single strong and multiple weak symbols, choose the strong symbol.
3. Given multiple weak symbols, choose any of the weak symbols.

Once the linker jas resolved all the symbols, each symbol reference has exectly one definition.
At this point linker starts the process of relocation, which involves:
- Relocationg sections and symbol definitions, All sections of the same type are merged into a new
  single section. For example, all .data sections of all input object filers are merged into a single
  .data section of the final executable. The linker then assigns runtimr memore addresses to new
  aggregate sections and also to each symbol. Now every instruction and global variable has a unique
  loadtime address.
- Relocating symbol reference within sections. In this step, linker modifies every symbol reference
  in the code and data sections so they point to the correct loadtime addresses.

https://www.linuxjournal.com/article/6463
---------------------------------------------------------------------------------------------------------
                             Linking and C runtime
---------------------------------------------------------------------------------------------------------
The linker adds an interface to the OS for us, and it is that interface that calls main().
The actual entry point that the linker uses by default is the symbol with the name _start.
When we link with gcc, it automatically includes a _start routine, one that sets up argc
and argv, among other things, and then calls main(). To avoid including this routine, we
can compile with `-nostartfiles`
    nasm -f elf tiny.asm
    gcc -Wall -s -nostartfiles tiny.o
    ./a.out
This code will still contain _exit procedure. _Start is not a function, it is a label that
linker uses as entry point, therefore we can`t return from it. To return from _start, we
can issue exit(), to clean up resources on process side, or _exit to exit right away.
It takes one dword from stack, whih is program status and returns to OS. We can remove
_exit from out executable using `-nostdlib`, like
    gcc -Wall -s -nostdlib tiny.o
However, now we are required to implement _exit on our own, using exit system call.
System all number is assigned to ax, and value to bx
_start
    mov eax, 1
    mov ebx, 42
    int 0x80
Now we can check size of the executable and try to keep making it smaller
    nasm -f elf tiny.asm
    gcc -Wall -s -nostdlib tiny.o
    wc -c a.out # ~372 bytes
We are still left with empty or unusefull sections of the file, that can be seen with objdump
    objdump -x a.out 

Default address for executables to be loaded is 0x08048000, however anything above 0x0 and page aligned
is valid

http://www.muppetlabs.com/~breadbox/software/tiny/teensy.html
=========================================================================================================
                                      Elf
=========================================================================================================
Every ELF file begins with a 52byte long ELF header, which contains several pieces of information
that describe the contents of the file. For instnace, first 16 bytes contain and "identifier", which
includes the file`s magic-number signature (7F 45 4C 46), and some one byte flags inficating that the
contents are 32bit or 64bit, little-endian or big-endian, target architecrute, whether file is
executable/object file/shared-object library, program starting address and location of two tables.
These two tables are program header table and section header table and they can appear anywhere in the
file ,but typically the former appears immediately following the ELF header, and the latter appears near
the end of the file. They have similar purpose, they identify the component parts of the file.

Section header table focuses more on identifying where the various parts of the program are within the file,
and is used by compiler and linker. It is optional for executables but is almost always present. This may
containt comment section, or bss section for executable that do nothing, which can be an overhead.

Program header table describes where and how these parts are to be loaded into memory, it is used by loader.
It is optional for object files, and in practise is never present

---------------------------------------------------------------------------------------------------------
                                 ELF Structure
---------------------------------------------------------------------------------------------------------
ELF Header 
.text       => machine code of the compiled program
.rodata     => read-only datam such as the format strings in the printf statements
.data       => initialized global variables
.bss        => Block Storage Start, uninitialized global variables
.symtab     => symbol table, information about functions and global variables
.rel.text   => list of locations in the .text that need to be modified when linker comnines object files
.rel.data   => relocation information for reference global variables not defined in the current module
.debug      => debugging symbol table
.line       => mapping between instruction line and C code line for debugger
.strtab     => string table for symbol table and .debug ?

http://www.cirosantilli.com/elf-hello-world/
=========================================================================================================
                                     Loader
=========================================================================================================
The loader is a program called execve, which loads the code and data of the executable object file
into memory and then runs the program by jumping to the first instruction. 

=========================================================================================================
                                Init vs Systemd
=========================================================================================================
Init is a daemon process which starts as soon as the computer starts and continue running till, it is
shutdown. It is the first process after boot, making it the parent of all other running processes directly
or indirectly and hence typically it is assigned pid=1. If init couldn`t  stat you will receive kernel
panic. There are many replacements for init, some of which are:
1. Upstart. Implemented in Ubuntu and designed to start process asynchronously
2. Epoch. Daemon built around simplicity and service managment, designed to start process single-threaded
3. Mudar. Daemon written in Python, implemented on Pardus and designed to start processes asynchronously
4. System. Daemon designed to start process in parallel, implemented in a number of standart distribution.

Init starts serially, one task starts only after last task startup was successful which resulted in
delayed and long booting time. Systemd is parallel
=========================================================================================================
                               Linux init scripts
=========================================================================================================
Init scripts are saved to /etc/rc.d, where you can find rc[1-6].d directories and rcS.d. File used to
be executed are defined in /etc/inittab. Here we define default runlevel and the files that wll be used
by that runlevel.
id:4:initdefault:l         # default level
1:4:wait:/etc/rc.d/rc.4    # directory where scripts for this level are saved
You can restart system into specific level using `init <n_level>`

There is as well rcS.d which is executed before any runlevel. After completing the boot process, init
executes all start scripts in a directory specified by default runlevel.

Here rc stands for run control and scripts have names of the form `[KS][0-9][0-9]*` where K stands for
kill and S for start. All these scripts are links to scripts in /etc/init.d/ directory.

If you don`t have inittab then probably you use another init system like firestart or systemd. They
will read configuration file in /etc/init/rc-sysinit.conf

To detect active inite system issue one of following
ps -p 1
file /sbin/init                        # will show full path behind link

https://unix.stackexchange.com/questions/18209/detect-init-system-using-the-shell
https://www.debian.org/doc/manuals/debian-faq/ch-customizing.en.html
https://stackoverflow.com/questions/38934978/meaning-of-the-name-of-linuxs-rcs-script
=========================================================================================================
                                    Systemd
=========================================================================================================
systemd is a system service manager for Linux that runs as a daemon with PID 1. It is compatible with SysV
init scripts and can work as a drop-in replacement for sysvinit. Features:
- Parallelization capabilities
- Uses socket and D-Bus activation for starting services
- Offers on-demand starting of daemons ?
- Tracks processes using Linux cgroups
- Supports snapshoting and restoring
- Maintains mount and automount points

=========================================================================================================
                              D-Bus (Desktop Bus)
=========================================================================================================
D-Bus is an IPC mechanism designed to replace the software component communications systems used by the
GNOME and KDE Linux desktop environments. Due to the large number of processes involved - adding up
processes providing  the servoces and clients accessing them - establishing one-to-one IPC communications
between all of them becomes an inefficient approach. D-Bus provides a software-bus abstraction that gathers
all the communications between a group of processes over a single shared virtual channel. 

Linux uses many of buses:
Single system bus interconnects system services and user processes
Single session bus for each user login session, that provides desktop services to user applications in
the same desktop session, and allows the integration of the desktop session as whole?


=========================================================================================================
                                   Run Levels
=========================================================================================================
A runlevel is one of the modes that a Unix -based operating system will run in. Each runlevel has a certain
number of services stopped or started, giving the user control over the behavior of the machine.

S - true single user mode usually drops you into a minimal root shell
1 - Administrative mode, you get a standard login request before access
2 - Multi-user without TCP/IP networking -- could use serial ports for other logins
3 - Multi-user with TCP/IP networking and text
4 - To be determined by the system owner
5 - Multi-User with TCP/IP networking and graphic console
6 - reboot
0 - shutdown and power down

To get current run level issue `who -r`

https://www.networkworld.com/article/3222070/maneuvering-around-run-levels-on-linux.html
=========================================================================================================
                              User/Group managment
=========================================================================================================
To check current logged in users and terminal that they use, issue who. Expacted result is one tty7 per
user which is used by xorg and represnets physical terminal used by client (computer) and as many pts
as user uses. Ther is option to call `who am i`, which return curent pts and its creation time.

There are multiple way to manage user under linux: using GUI, cli tools or just editing configuration files.
Local user database is saved under /etc/passwd, where user are save in form like
mysql:x:126:135:MySQL Server,,,:/nonexistent:/bin/false
where each column denotes 
user :?:userid:primary group id:description    :home directory:login shell
mysql:x:126   :135             :MySQL Server,,,:/nonexistent  :/bin/false

To manage user from cli you have two sets of tools, user{add,del,mod} and {add,del}user where latter are
frontend scripts in perl for first set. I will describe useradd here. You need to create user and set
password for him with following commands
useradd -m -d <path> -c <name> <name> 
        -m           # create home
        -d  <path>   # home directory
        -c  <name>   # comment, used as the field for the user`s full name
        -D           # display defaults for user
        -D <options> # change defaults for user
        -k <path>    # skeleton dir copied to users $HOME
        -G <name>    # list of groups user will be added to

passwd <name>        # set password

Group manipulation
addgroup <name>               # create group
adduser  <user> <group>       # add user to group
usermode -aG <group> <user>

Default behavious can be specified within /etc/default/useradd or /etc/adduser.conf
---------------------------------------------------------------------------------------------------------
                                  Permissions
---------------------------------------------------------------------------------------------------------
Every file on a GNU/Linux system is owned by a user and a group. In addition, there are three types of
access permissions: read, write, and execute. Different access permissions can be applied to a file's
owning user, owning group, and others (those without ownership). One can determine a file's owners and
permissions by viewing the long listing format of the ls or stat command:
ls -l <path>
rights     | |user|user group |      |      |     | name
drwxrwxr-x  3 vova volodymyr     4096 jun 21  2018 books

Access permissions are displayed in three groups of characters, representing the permissions of the owning
user, owning group, and others, respectively. To find all files owned by group or user, issue
find / -group groupname
find / -group groupnumber

find / -user user
Rights have next form
type      | user  |groups |others
d / -     |rw(x|s)|rw(x|s)| rwx
and can be changed using chmod or chown

---------------------------------------------------------------------------------------------------------
                              Special permissions
---------------------------------------------------------------------------------------------------------
By default the ownership of files is based on uid/gid of the user who have created them, the same rule
applies to launching a process. This can be changed using a special type of permission flags.

---------------------------------------------------------------------------------------------------------
SUID (Set User ID)
---------------------------------------------------------------------------------------------------------
When an executable is launched, it runs with the privileges of the file owner. If file is owned by root
and has SUID bit set, when launched by a normal user, it will run with root privileges.
Example, `passwd` is accessible by any user so he can change his password.
  $ chmod 4775 test
  $ chmod u+s test
  $ ls -l /bin/passwd
      -rwsr-xr-x. 1 root root 27768 Feb 11  2017 /bin/passwd
Where `s` implies `suid + x`, while `S` only `suid`
---------------------------------------------------------------------------------------------------------
SGID (Set Group ID)
---------------------------------------------------------------------------------------------------------
The SGID bit on a directory means that any files created in that directory will be owned by group that
owns the directory, regardless of who created them. It is marked as an `s` in place of `x` where group
permission go.
  $ chmod 2775 test
  $ chmod g+s <dir/file>

Causes files to be executed with group owner permissions.
On directories makes all new files to be created with the same group id as directory.

---------------------------------------------------------------------------------------------------------
Sticky bit
---------------------------------------------------------------------------------------------------------
There is a situation when you want to have a directory accessible by all but file modifiable by it`s owners
only. This can be done with Sticky bit and is used for `/tmp` files
  $ chmod 1775 test
  $ chmod o+t test
  $ ls -ld /tmp
    drwxrwxrwt. 14 root root 300 Nov  1 16:48 /tmp
Where `t` implies both Sticky + `x`, while `T` implies only Sticky bit

---------------------------------------------------------------------------------------------------------
                                      UID
---------------------------------------------------------------------------------------------------------
UIDs below 1000 are typically reserved for system accounts.  Root has always UID 0 and conventially
UID 65534 is nobody. UID ranges allocation can be found in `/etc/login.defs`

Debin related rules
https://unix.stackexchange.com/questions/254245/what-is-an-appropriate-uid-and-gid-for-a-debian-package-file-owner
https://stackoverflow.com/questions/1013516/what-are-the-well-known-uids
---------------------------------------------------------------------------------------------------------
                               Adduser vs Useradd
---------------------------------------------------------------------------------------------------------
useradd is native binary compiled with the system. while adduser is a perl script which uses useradd binary
in back-end. adduser is more user friendly and interactive. It should be used by administrator since it
by default chooses Debian policy conformant UID and GID values, creates home directory with skeletal
configuration and other features. If you writing some low level scripts ,that should be portable, useradd
is prefered. 

https://askubuntu.com/questions/345974/what-is-the-difference-between-adduser-and-useradd
---------------------------------------------------------------------------------------------------------
                            Chown vs Chmod vs Chgrp
---------------------------------------------------------------------------------------------------------
chmod => change mode, allows changing permissions of files/folders (also known as `modes` in UNIX).
chown => change owner, allows changing owner od files/folders.
chgrp => change group, allows changing file group

The chmod can be used in couple different ways, with permissios set by numbers or letters
chmod [-R][ugo][+-=][rwx/421] <file>
+ to increase permissions
- to cancell permissions
= to save?

chmod
    -C      # display file whose permitions have changed
    -F      # don`t dissplay error messages
    -V      # show details of permission changes

# all permissions for owner and rx for others
chmod 755 <file>
chmod u+rwx,go+rx <file>

chown [-R]<user>[:<group>] <path> # makes <user> from group <group> owner of file <path>
chown <user> <file>
chown <user:group> <file>

chgrp <group> <file>

---------------------------------------------------------------------------------------------------------

chown -R <user>:<group> <directory>

/etc/group          : list of all groups 
/etc/passwords      : password for all users 
    can change home directory for user
    can change shell path 
    no passwords are saved here (encrypted) , are in file /etc/shadow but encrypted

Set default permissions for directory
setfacl -d -m #(g|u|o)::rwx #dir
getfacl #dir

https://askubuntu.com/questions/971836/at-what-point-is-the-bashrc-file-created
=========================================================================================================
                               Session managment
=========================================================================================================
Session usually refers to shell sessions. A new session is launched every time you open a terminal

=========================================================================================================
                               Process managment
=========================================================================================================
echo $$         # current shell pid
echo $!         # pid of previous process ?
echo $PPID      # parent pid

=========================================================================================================
                                Network manager
=========================================================================================================
Only devices that are not listed in /etc/network/interfaces or which have been configured "auto" and "dhcp"
(with no other options) are managed by NM.  To disable managment of interface by NM
1.Put next to /etc/NetworkManager.conf
[main]
plugins=keyfile
[keyfile]
unmanaged-devices=mac:xx:xx:xx:xx:xx:xx,
                  interface-name:name...

Then restart networking and manager services
sudo /etc/init.d/networking restart
sudo service network-manager restart

2. Change 'managed' under config to false, then interfaces configured from /etc/network/interfaces won`t
   be managed by NM

https://stackoverflow.com/questions/5321380/disable-network-manager-for-a-particular-interface

=========================================================================================================
                            Tar vs Gz vs Zip vs Cpio
=========================================================================================================
.tar ## uncompressed archive file
.zip ## usually compressed archive file
.gz  ## file (not always archive) compressed using gzip

Compressed tar files is native for Linux  mechanism for sharing files although it is also common to find
other compressed formats such as .bz2 that use different compression algorithms.
ZIP is only really used to share files with Windows users. It may not support all the Unix file system
metadata reliably. 
cpio was originally designed to store backup file archives on a tape device in a sequential, contiguos manner.
It does not compress any content, but resulting archives are often compressed using gzip or other compressors.
tar is prefered over cpio due to its relative simplicity, it can take input files as arguments instead of
reading STDIN. 

find myfiles -depth -print0 | cpio -ovc0 | gzip -7 > myfiles.cpio.gz
tar czvf myfiles.tar.gz myfiles

https://itsfoss.com/tar-vs-zip-vs-gz/
https://superuser.com/questions/343915/what-is-the-difference-between-tar-vs-cpio-archive-file-formats
https://www.quora.com/What-is-the-difference-between-tar-gz-zip-and-tar-gz-in-Linux
=========================================================================================================
                                  Tar/Zip/Gzip/Rar
=========================================================================================================
tar (Tape ARchive) is used for archiving, therefore don`t expect to see compression. To compress archive
you can use gzip/bzip2/xz. For conviniece tar has flag to compress archive automatically for you. Type of
compression is determined by file extension

tar
    -z            # invoke gunzip transparently for  .gz, .tgz, .tar.fz
    -j            # working with bzip2
    -x            # extract files from archive
    -v            # verbose
    -f            # archive file to be extracted
    -C            # change directory were archive will be extracted
    -c            # create archive
    -A            # append files to archive
    -d            # diff between two archives

tar -zxvf file                      # uncompress file .tgz or .tar.gz
tar xvjf file.tar.bz2               # uncompress .tbz / .bz2
tar xvf file.tar                    # to uncompressed tar file (.tar) 
tar xv -C <dir> -f <tar>            # to uncompress tar file (.tar) to another directory 
tar -czv -f test.tar.gz /www/*      # compress directory
tar -xvzf <tar> <file>              # extract file from tarball
tar -tvf <tar>                      # list content of tar

The .gz file extension are created using Gzip program which reduces the size of the named files using
Lempel-Ziv coding (LZ77). gzip take input from stdin and outputs compress data to stdout.
gzip                                # gnu zip
     -d <file>                      # compress file (doesn`t require piping to stdin)
     -c <file>                      # uncompress -||- 

cat file{1,2} | gzip > foo.gz       # archive and copress file{1,2} to foo.gz
gzip -c file{1,2} > foo.gz
gzip -c file1 > foo.gz
gzip -c file2 >> foo.gz


=========================================================================================================
                                    Hardware
=========================================================================================================
use lshw to lookup info about hardware
lspci
lsusb
=========================================================================================================
                                     Distro
=========================================================================================================

lsb_release -a : ubuntu info
uname -a       : kernel info

=========================================================================================================
                                      SCP
=========================================================================================================
me/remote => hostname@ip/domain

scp username@hostname:file      # copy to me
scp file username@hostname      # copy to remote
scp -r dir username@hostname    # copy dir to remote
scp -r username@hostname:path . # copy folder from remote
scp me1@file me2@file   # cp from one user to another

# SCP will break if init script does echo

=========================================================================================================
                                     Patch
=========================================================================================================
Patch => compact representation of the differences between two files, intended for use with line-oriented
text files.

When patch fails to apply a patch segment to the original file, it saves the temporary original file copy
out as *.orig, dumps the rejected segments to *.rej, and continues trying to apply patch segments. The
idea is that you can open the *.rej file and complete the patch process manually by copying bits and pieces
over to the patched file. If patch was applied but some offsets were changes, patch will save .orig file.

patch
      -b         # create backup (for cases when you applie patch not to git, and wont have option to
                   checkout file after bad patch)
      -i <patch> # read from file instead of stdin
      -p <n>     # strip n slashes from the filepath to the filename
                 # if not present, file name /path../../file_name is stripped to file_name
                 # -p0 gives path with leading /a/b or without? TODO test
      -R         # revert patch
   --merge=merge # default, like git merge?
           diff3 # has additional section with original content
                   <<<<<<<
                   lines from the original file
                   |||||||
                   original lines from the patch
                   =======
                   new lines from the patch
                   >>>>>>>

diff 
      -u[n]      # unified diff (one that is expected by ), n specifies number of lines of context
                   by default 3.
      -N         # treat  absent files as being emptya

---------------------------------------------------------------------------------------------------------
                              Breaking an example
---------------------------------------------------------------------------------------------------------
diff --git a/foo.c b/foo.c
Suggests the notion of a Git-specific diff in Unix command style.  a/foo.c and b/foo.c are the files being
compared, with added leading directory names a and b to distinguish them in case they are the same (as
they are here; this patch shows the changes from one version to another of the same file)
There are in fact no directories named a and b in the repository; they are just convention.

index 30cfd169..8de130c2 100644
This line gives information from the Git index regarding this file: 30cfd169 and 8de130c2 are the blob
IDs of the A and B versions of the file contents being compared, and 100644 are the “mode bits,” indicating
that this is a regular file: not executable and not a symbolic link
There may be more lines describing if file name or modes were changed...
If those blobs are in the object database, then Git can use them to perform a three-way merge with those
two versions and the working copy, to help you resolve the conflicts.
Utility like patch can still use such diff but it may ignore usefull git specific information

--- a/foo.c
+++ b/foo.c
This is the traditional “unified diff” header, again showing the files being compared and the direction
of the changes

@@ -1,5 +1,5 @@
... Some code prefixed with '+- '
This is a difference section, or “hunk”. Lines starting with space are context

https://www.git-tower.com/learn/git/ebook/en/command-line/advanced-topics/diffs
https://www.oreilly.com/library/view/git-pocket-guide/9781449327507/ch11.html
---------------------------------------------------------------------------------------------------------
=========================================================================================================
                                   Memory CLI
=========================================================================================================
free               # list RAM/Swap memory usage
        -m         # in MB
        -h         # human readable
cat /proc/meminfo  # allot of different system buffers
vmstat             # memory usage statistics
dmidecode          # get hardware info for your RAM


---------------------------------------------------------------------------------------------------------
                                      TOP
---------------------------------------------------------------------------------------------------------
RSS (Resident Set Size) => how much memory is allocated to the process and in in RAM. Doesn`t include memory
that is swapped out. It does include memory from shared libraries whose pages are in memory. Includes all
stack and heap memory. Since part of the memory is shared, many processes may use it, so if you add up all
of the RSS values you can easily end up with more space than your system has.

VSZ (Virtual Memory Size) => all memory process can access, including memory that is swapped out, that is
allocated but not used and memory from shared libraries.

The memory that is allocated also may not be in RSS until it is actually used by the program. So if your
program allocated a bunch of memory up front, then uses it over time, you could see RSS going up and VSZ
staying the same.

https://stackoverflow.com/questions/7880784/what-is-rss-and-vsz-in-linux-memory-management
=========================================================================================================
                                       PS
=========================================================================================================
Codes:
D 	Uninterruptible sleep (usually IO)
R 	Running or runnable (on run queue)
S 	Interruptible sleep (waiting for an event to complete)
T 	Stopped, either by a job control signal or because it is being traced.
X 	dead (should never be seen)
Z 	Defunct ("zombie") process, terminated but not reaped by its parent.

Brackets aroung process means that it was not possible to detect command line arguments. Mostly, it is
kernel threads and some system services. Setting argv[0] to empty string may result in the same output?

To find parent of proccess pid, issue
ps -o ppid=$pid
ps -f $pid
pstree -aps $pid    # for tree like outout
pstree -hp $pid     # straight tree
cat /proc/$pid/status | grep PPid:
cat /proc/$pid/stat # 4th parameter
=========================================================================================================
                                    Busybox
=========================================================================================================
BusyBox. The Swiss Army Knife of Embedded Linux. BusyBox combines tiny versions of many common UNIX
utilities into a single small executable. It provides minimalist replacements for most of the utilities
you usually find in GNU coreutils, util-linux, etc.

BusyBox is a multi-call binary. A multi-call binary is an executable program that performs the same job as
more than one utility program. That means there is just a single BusyBox binary, but that single binary
acts like a large number of utilities.

busybox                  # displays list of available utilities
        ls               # issue busybox version of the `ls` utility
ln -s /<path>/busybox ls # make link to busybox, equivalent to `busybox ls`
                         # note, it is expected that such links are configured by build system without user

It can be used as backup for cases when linux coreutils got broken on system, just linked broken binaries
to busybox and hope that it is not called with unknown, for busybox, flags.

https://busybox.net/downloads/BusyBox.html
=========================================================================================================
                              Troubleshooting
=========================================================================================================
                                      Boot
---------------------------------------------------------------------------------------------------------
To enter grub menu, press quickly left Shift? during boot

To boot system into shell, start from grup menu, choose boot img and issue `e`, this will open configuration
file. Here find line starting with `linux` and append `init=/bin/sh` to it. There is option to specify boot
level from here (any usefull purpose?). Common option that you will find on the same line are
# remove splashcreen (start login input screen)
# nomodeset to disable most of drivers
# no quite  to display status on screen

You can interrupt boot process to gain root shell by providing break=init etc. to the kernel boot parameter.
See /init source for more. 
---------------------------------------------------------------------------------------------------------
                                 Splash screen
---------------------------------------------------------------------------------------------------------
Splash screen is image displayed during system initialization after loggin, it is displayed while common
services are started from init scripts. This may hide an issue, when some crucial service failed to start
and instead of console with error you see splash screen picture, but probably it will try to display last?
error unless system is in critical state.
To remove initialization picture, remove splash from init line. To see logs, remove quite from init line.

To switch from splash screen to terminal issue `alt` + `F1` or `F2`
https://askubuntu.com/questions/248/how-can-i-show-or-hide-boot-messages-when-ubuntu-starts
---------------------------------------------------------------------------------------------------------
To make changes permament, change file /etc/default/grub and issue `sudo update-grub`.

If you need to access kernel log from previous sessions, like when something have crashed, issue
journalctl -o short-precise -k         # current boot
journalctl -o short-precise -k -b -1   # last boot
journalctl -o short-precise -k -b -<n> # nth boot
journalctl --list-boot                 # list of available boot logs
Otherwise you can take a look at /var/log/dmesg[n][.gz]

To specify defaul kernel version that will be used, you need to define GRUB_DEFAULT in `/etc/default/grub`
using menu entires from `/boot/grub/grub.cfg`, like
             | The menu entry           |>| The kernel entry             |
GRUB_DEFAULT="Advanced options for Ubuntu>Ubuntu, with Linux 5.4.0-custom"

---------------------------------------------------------------------------------------------------------
You can boot into BIOS from CLI using
sudo systemctl reboot --firmware-setup

---------------------------------------------------------------------------------------------------------
                                     Sound
---------------------------------------------------------------------------------------------------------
speaker-test -c2 
sudo apt install --reinstall alsa-base alsa-utils pulseaudio linux-sound-base libasound2
sudo add-apt-repository ppa:ubuntu-audio-dev
sudo apt-get update
sudo apt-get dist-upgrade



https://askubuntu.com/questions/426648/how-to-reinstall-pulseaudio-ubuntu-12-04
https://linuxhint.com/pulse_audio_sounds_ubuntu/
https://www.unixmen.com/2012003-howto-resolve-nosound-problem-on-ubuntu/
https://dev.to/setevoy/linux-alsa-lib-pcmdmixc1108sndpcmdmixopen-unable-to-open-slave-38on
https://help.ubuntu.com/community/SoundTroubleshootingProcedure
https://support.system76.com/articles/audio/
=========================================================================================================
                               Package managment
=========================================================================================================
You can package your solution what ever you want, but to make it portable, easy to use and share you
need to follow rules provided by OS distribution. Let`s supose that you have followed the rules, provided
special configuration/installation files and file structure, now we face the question: should we package
everything related to application as one package or multiple? The answer is that you need to separate
them: your user may not need header file if he won`t use them, or there is no need to install docs for
already experienced user. Therefore, package is divided into multiple packages with the same name but
different suffix. Common are -doc, -data, -dbg[sym], -dev, -common, -util, -all (means that for all
architectures)


Excepet from using the package, you may want to develop or debug it. In such case you will download
specially named version of the package *-dev, *-dbg. Dev package contains header files and statically
compiled versions of library files, sometimes additional documentation/examples or even helper apps.
This all let`s your own application`s based on interface provided by package.

dpkg -l                     # list installed packages
dpkg -L <package>           # list files installed by package
apt-file list <package>     # list files installed by package

https://www.debian.org/doc/manuals/maint-guide/advanced.en.html
https://askubuntu.com/questions/182703/how-and-why-to-create-dbg-dev-doc-packages
=========================================================================================================
                  PAM. Linux Pluggable Authentication Modules
=========================================================================================================
Mechanism that provide dynamic authentication support for applications and services in Linux system.
It integrates multiple low-level authentication modules into a high-level API that provides dynamic
authentication support for applications. This allows developers to write applications that require
authentication, independently of the underlying authentication system.

All authentication tasks are separated into four independent managment groups:
1. Account modules. Checks that the specified account is a valid authentication target under current conditions.
   Possible coniditions include: account expiration, time of day, access to the requested service.
2. Authentication modules. Verify the user's identity, for example by requesting and checking a password
   or other secret. They may also pass authentication information on to other systems like a keyring.
3. password modules. Responsible for updating passwords, and are generally coupled to modules employed
   in the authentication step. They may also be used to enforce strong passwords.
4. Session modules. Defines actions that are performed at the beginning and end of sessions.
   A session starts after the user has successfully authenticated.

PAM aware application use following files for configuration: /etc/pam.conf and the /etc/pam.d/.
These files contain rules of form:
  service | type | control-flag | module | module-arguments
- service      | actual application name.
- type         | module type/context/interface.
- control-flag | indicates the behavior of the PAM-API should the module fail to succeed in its
               | authentication task.
- module       | the absolute filename or relative pathname of the PAM.
- module-arguments: space separated list of tokens for controlling module behavior.
Note, there is no need to specify service for files in /etc/pam.d/
Some PAM modules require configuration files beside the PAM configuration to operate.
These module-specific configuration files are stored in /etc/security.

NOTE: Erroneous PAM configuration can disable access to your system partially, or completely.

https://dzone.com/articles/linux-pam-easy-guide
https://www.tecmint.com/configure-pam-in-centos-ubuntu-linux/
https://www.opennet.ru/base/dev/pam_linux.txt.html
=========================================================================================================
                               Package managment
=========================================================================================================
You can package your solution what ever you want, but to make it portable, easy to use and share you
need to follow rules provided by OS distribution. Let`s supose that you have followed the rules, provided
special configuration/installation files and file structure, now we face the question: should we package
everything related to application as one package or multiple? The answer is that you need to separate
them: your user may not need header file if he won`t use them, or there is no need to install docs for
already experienced user. Therefore, package is divided into multiple packages with the same name but
different suffix. Common are -doc, -data, -dbg[sym], -dev, -common, -util, -all (means that for all
architectures)


Excepet from using the package, you may want to develop or debug it. In such case you will download
specially named version of the package *-dev, *-dbg. Dev package contains header files and statically
compiled versions of library files, sometimes additional documentation/examples or even helper apps.
This all let`s your own application`s based on interface provided by package.

dpkg -l                     # list installed packages
dpkg -L <package>           # list files installed by package
apt-file list <package>     # list files installed by package

https://www.debian.org/doc/manuals/maint-guide/advanced.en.html
https://askubuntu.com/questions/182703/how-and-why-to-create-dbg-dev-doc-packages
=========================================================================================================
                  PAM. Linux Pluggable Authentication Modules
=========================================================================================================
Mechanism that provide dynamic authentication support for applications and services in Linux system.
It integrates multiple low-level authentication modules into a high-level API that provides dynamic
authentication support for applications. This allows developers to write applications that require
authentication, independently of the underlying authentication system.

All authentication tasks are separated into four independent managment groups:
1. Account modules. Checks that the specified account is a valid authentication target under current conditions.
   Possible coniditions include: account expiration, time of day, access to the requested service.
2. Authentication modules. Verify the user's identity, for example by requesting and checking a password
   or other secret. They may also pass authentication information on to other systems like a keyring.
3. password modules. Responsible for updating passwords, and are generally coupled to modules employed
   in the authentication step. They may also be used to enforce strong passwords.
4. Session modules. Defines actions that are performed at the beginning and end of sessions.
   A session starts after the user has successfully authenticated.

NOTE: Erroneous PAM configuration can disable access to your system partially, or completely.
=========================================================================================================
Random
=========================================================================================================
---------------------------------------------------------------------------------------------------------
                           Copy-merge two directories
---------------------------------------------------------------------------------------------------------
rsync -vha --progress /src_path/ /dst_path/

https://unix.stackexchange.com/questions/149965/how-to-copy-merge-two-directories
---------------------------------------------------------------------------------------------------------
                                  Linux Files
---------------------------------------------------------------------------------------------------------
/etc/services      # The services translation 
/proc/net/dev      # Device network stats
/etc/hosts         # maps ip to domain name : is checked before dns lookup
/etc/resolv.cond   # saves ip of dns servers
/etc/services      # contains ports with services
/etc/protocols     # ports?


/dev     : device dir
/proc    : proces dir
/sys    : system dir

/lost+find         # directory constructed by fsck (file system check) to 
                   # it holds things that were found in memory and looks like file
                   # but there is no name/inode... so they can be restored
                   # Can contain result of system halt , kernel panic, power failure ...

---------------------------------------------------------------------------------------------------------
                               /proc of interest
---------------------------------------------------------------------------------------------------------

malloc                  # malloc debugging
meminfo                 #


[pid]
    /attr               # security
    /exe                # symlink to the executable
    /comm               # executable name
    /cmdline            # passed arguments
    /cwd
    /map_files          # files responding to mmap
    /maps               # currently mapped memory regions and their permissions
    /root               # root mounted for process
    /smaps              # mem consumptions for each of process mappings
                        # see pmap(1)
    /statm              # memory usage, measured in pages
    /status             # stat + statm mostly in more readable format
    /timers             # list of proc timers

 /stack              # kernell stack?


=========================================================================================================
sudo add-apt-repository ppa:graphics-drivers/ppa
sudo apt update
sudo ubuntu-drivers devices     # lists capable drives and recommends one
sudo apt-get install nvidia-<num>
sudo ubuntu-drivers autoinstall

# install default nouveau driver
sudo apt-get autoremove --purge nvidia-*
sudo service lightdm stop
sudo apt-get install xserver-xorg-video-nouveau

# pulse
sudo apt-get --purge --reinstall install pulseaudio

/proc/driver/nvidia/version
/proc/driver/nvidia/warnings
/proc/driver/nvidia/gpus/domain:bus:device.function/information
https://download.nvidia.com/XFree86/Linux-x86_64/340.108/README/commonproblems.html
modprobe -r nouveau
/var/log/Xorg.0.log
sudo X -configure
 /etc/X11/xorg.conf
https://askubuntu.com/questions/28033/how-to-check-the-information-of-current-installed-video-drivers

systemctl isolate multi-user.target     # lvl 3
systemctl isolate graphical.target      # lvl 5

cat  ~/.local/share/xorg/Xorg.0.log

=========================================================================================================
TODO
=========================================================================================================
Debian packages
https://iomem.com/archives/18-Avoiding-tests-when-building-Debian-packages.html
https://unix.stackexchange.com/questions/418354/understanding-what-a-linux-binary-is-doing
=========================================================================================================
Links
=========================================================================================================
htt://github.com/0xAX/linux-insides/blob/master/Booting/linux-bootstrap-1.md
https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/
https://github.com/torvalds/linux/blob/v4.16/Documentation/x86/boot.txt
https://github.com/shellphish/how2heap
https://github.com/dylanaraps/pure-bash-bible
https://github.com/s-matyukevich/raspberry-pi-os
https://www.tldp.org/HOWTO/text/Linux-Init-HOWTO
https://0xax.github.io/stack_layout_x86_64/

https://kernelnewbies.org/WikiWikiWeb
https://elixir.bootlin.com/linux/latest/source
https://www.kernel.org/doc/html/v4.10/process/howto.html
https://wiki.osdev.org/Introduction


https://www.tldp.org/HOWTO/text/Linux-Init-HOWTO

https://vincent.bernat.ch/en/blog/2017-ipv4-route-lookup-linux
